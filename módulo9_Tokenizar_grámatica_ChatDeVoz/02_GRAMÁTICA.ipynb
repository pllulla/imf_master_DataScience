{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ab2a601",
   "metadata": {},
   "source": [
    "- Eliminar contexto y dejar contexto\n",
    "- Eliminar contexto para análisis cuantitatívo de las palabras (densidad, conteo, etc)\n",
    "- Dejar contexto para estraer información de las palabaras (gramaticalmente, significado, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fffc0",
   "metadata": {},
   "source": [
    "### Gramatica con el contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9629f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.chunk.regexp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "407a63ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'want', 'a', 'dress', 'for', 'a', 'wedding']\n"
     ]
    }
   ],
   "source": [
    "ejemplo =\"I want a dress for a wedding\"\n",
    "tokens = word_tokenize(ejemplo)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b870d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_min = [w.lower() for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96f3373e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'NN'),\n",
       " ('want', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('dress', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('wedding', 'NN')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')\n",
    "nltk.pos_tag(tokens_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed096895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,312.0,120.0\" width=\"312px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"10.2564%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">i</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.12821%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"15.3846%\" x=\"10.2564%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">want</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"17.9487%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"10.2564%\" x=\"25.641%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.7692%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"17.9487%\" x=\"35.8974%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">dress</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"44.8718%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"12.8205%\" x=\"53.8462%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">for</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"60.2564%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"10.2564%\" x=\"66.6667%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"71.7949%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"23.0769%\" x=\"76.9231%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">wedding</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.4615%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [('i', 'NN'), ('want', 'VBP'), ('a', 'DT'), ('dress', 'NN'), ('for', 'IN'), ('a', 'DT'), ('wedding', 'NN')])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')\n",
    "entities = nltk.chunk.ne_chunk(nltk.pos_tag(tokens_min))\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b80bf98",
   "metadata": {},
   "source": [
    "Palabras libres de contexto\n",
    "- Creamos categorias para las palabras, las palabras pasan por cada una y se etiquetan en cada categoria. Las palabras pasan varias veces por las categorias pq pueden pertenecer a más de una. Una palabra puede ser un pronombre y un determinante, por ejemplo. Se llenan de abajo a arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c397ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'i'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'a'\n",
    "N -> 'dress' | 'wedding'\n",
    "V -> 'want'\n",
    "P -> 'for'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b20a75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "def parsear(_tokens):\n",
    "    return parser.parse(_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "776cd2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sale en una ventana nueva\n",
    "for tree in parsear(tokens_min):\n",
    "    tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ca24539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP i)\n",
      "  (VP\n",
      "    (VP (V want) (NP (Det a) (N dress)))\n",
      "    (PP (P for) (NP (Det a) (N wedding))))) \n",
      "\n",
      "     S                                    \n",
      "  ___|_____________                        \n",
      " |                 VP                     \n",
      " |         ________|________               \n",
      " |        VP                PP            \n",
      " |    ____|___           ___|___           \n",
      " |   |        NP        |       NP        \n",
      " |   |     ___|____     |    ___|_____     \n",
      " NP  V   Det       N    P  Det        N   \n",
      " |   |    |        |    |   |         |    \n",
      " i  want  a      dress for  a      wedding\n",
      "\n",
      "(S\n",
      "  (NP i)\n",
      "  (VP\n",
      "    (V want)\n",
      "    (NP (Det a) (N dress) (PP (P for) (NP (Det a) (N wedding)))))) \n",
      "\n",
      "     S                                \n",
      "  ___|_________                        \n",
      " |             VP                     \n",
      " |    _________|____                   \n",
      " |   |              NP                \n",
      " |   |     _________|___               \n",
      " |   |    |    |        PP            \n",
      " |   |    |    |     ___|___           \n",
      " |   |    |    |    |       NP        \n",
      " |   |    |    |    |    ___|_____     \n",
      " NP  V   Det   N    P  Det        N   \n",
      " |   |    |    |    |   |         |    \n",
      " i  want  a  dress for  a      wedding\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tree in parsear(tokens_min):\n",
    "    print(tree, '\\n')\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a8d999",
   "metadata": {},
   "source": [
    "Ejemplo con frase en Español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4719d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['me', 'gusta', 'llegar', 'puntual', 'a', 'clase']\n"
     ]
    }
   ],
   "source": [
    "frase = \"me gusta llegar puntual a clase\"\n",
    "tokens = word_tokenize(frase)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b34b32b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('me', 'PRP'),\n",
       " ('gusta', 'JJ'),\n",
       " ('llegar', 'JJ'),\n",
       " ('puntual', 'FW'),\n",
       " ('a', 'DT'),\n",
       " ('clase', 'NN')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_min = [w.lower() for w in tokens]\n",
    "nltk.pos_tag(tokens_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c594138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"120px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,320.0,120.0\" width=\"320px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"12.5%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">me</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"6.25%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"17.5%\" x=\"12.5%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">gusta</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"21.25%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"20%\" x=\"30%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">llegar</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"40%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"22.5%\" x=\"50%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">puntual</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">FW</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.25%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"10%\" x=\"72.5%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"77.5%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"17.5%\" x=\"82.5%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">clase</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"91.25%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [('me', 'PRP'), ('gusta', 'JJ'), ('llegar', 'JJ'), ('puntual', 'FW'), ('a', 'DT'), ('clase', 'NN')])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entidades = nltk.chunk.ne_chunk(nltk.pos_tag(tokens_min))\n",
    "entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c338f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> Pronoun\n",
    "VP -> V Infinitive Adverb PP\n",
    "Infinitive -> 'llegar'\n",
    "Adverb -> 'puntual'\n",
    "PP -> P N\n",
    "V -> 'gusta'\n",
    "Pronoun -> 'me'\n",
    "P -> 'a'\n",
    "N -> 'clase'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2bf404c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  S                           \n",
      "    ______________|_________                   \n",
      "   |                        VP                \n",
      "   |       _________________|_________         \n",
      "   NP     |       |         |         PP      \n",
      "   |      |       |         |      ___|____    \n",
      "Pronoun   V   Infinitive  Adverb  P        N  \n",
      "   |      |       |         |     |        |   \n",
      "   me   gusta   llegar   puntual  a      clase\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "def parsear(_tokens):\n",
    "    return parser.parse(_tokens)\n",
    "\n",
    "for tree in parsear(tokens_min):\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21c823",
   "metadata": {},
   "source": [
    "OTRO EJEMPLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb3c1f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['la', 'abuela', 'bebe', 'vodka', 'y', 'fuma', 'porros']\n"
     ]
    }
   ],
   "source": [
    "frase3 = \"La abuela bebe vodka y fuma porros\"\n",
    "tokens3 = word_tokenize(frase3)\n",
    "tokens3_min = [w.lower() for w in tokens3]\n",
    "print(tokens3_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce969b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar3 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> Otros Suj Accion Otros Accion\n",
    "Suj -> Persona\n",
    "Accion -> V N\n",
    "Persona -> 'abuela'\n",
    "V -> 'bebe' | 'fuma'\n",
    "N -> 'vodka' | 'porros'\n",
    "Otros -> 'y' | 'la'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "069f97fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            S                           \n",
      "   _________________________|________________            \n",
      "  |     Suj        Accion         |        Accion       \n",
      "  |      |      _____|______      |     _____|______     \n",
      "Otros Persona  V            N   Otros  V            N   \n",
      "  |      |     |            |     |    |            |    \n",
      "  la   abuela bebe        vodka   y   fuma        porros\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammar3)\n",
    "\n",
    "for tree in parsear(tokens3_min):\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab6e45aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['la', 'mujer', 'compra', 'un', 'coche']\n"
     ]
    }
   ],
   "source": [
    "frase4 = \"La mujer compra un coche\"\n",
    "tokens4 = word_tokenize(frase4)\n",
    "tokens4_min = [w.lower() for w in tokens4]\n",
    "print(tokens4_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d14c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar4 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> Otros Suj Accion Otros Accion | Otros Suj Accion\n",
    "Suj -> Persona\n",
    "Accion -> V N | V Otros N\n",
    "Persona -> 'abuela' | 'mujer'\n",
    "V -> 'bebe' | 'fuma' | 'compra'\n",
    "N -> 'vodka' | 'porros' | 'coche'\n",
    "Otros -> 'y' | 'la' | 'un'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b36f134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                S                \n",
      "   _____________|______           \n",
      "  |     Suj          Accion      \n",
      "  |      |       ______|______    \n",
      "Otros Persona   V    Otros    N  \n",
      "  |      |      |      |      |   \n",
      "  la   mujer  compra   un   coche\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammar4)\n",
    "\n",
    "for tree in parsear(tokens4_min):\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a65f2379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pepe', 'y', 'maría', 'cocinan', 'brownies']\n"
     ]
    }
   ],
   "source": [
    "# \"Pepe y María cocinan brownies\"\n",
    "frase5 = \"Pepe y María cocinan brownies\"\n",
    "tokens5 = word_tokenize(frase5)\n",
    "tokens5_min = [w.lower() for w in tokens5]\n",
    "print(tokens5_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "01e81240",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar5 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> Otros Suj Accion Otros Accion | Otros Suj Accion | Suj Accion\n",
    "Suj -> Persona | Persona Otros Persona\n",
    "Accion -> V N | V Otros N\n",
    "Persona -> 'abuela' | 'mujer' | 'pepe' | 'maría'\n",
    "V -> 'bebe' | 'fuma' | 'compra' | 'cocinan'\n",
    "N -> 'vodka' | 'porros' | 'coche' | 'brownies'\n",
    "Otros -> 'y' | 'la' | 'un'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0f72a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 S                           \n",
      "           ______|______________              \n",
      "         Suj                  Accion         \n",
      "    ______|______         ______|_______      \n",
      "Persona Otros Persona    V              N    \n",
      "   |      |      |       |              |     \n",
      "  pepe    y    maría  cocinan        brownies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammar5)\n",
    "\n",
    "for tree in parsear(tokens5_min):\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0da1e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['maría', 'ha', 'robado', 'un', 'huevo', 'de', 'avestruz', 'del', 'zoo']\n"
     ]
    }
   ],
   "source": [
    "frase6 = \"María ha robado un huevo de avestruz del zoo\"\n",
    "tokens6 = word_tokenize(frase6)\n",
    "tokens6_min = [w.lower() for w in tokens6]\n",
    "print(tokens6_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "69ae840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar6 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> Otros Suj Accion Otros Accion | Otros Suj Accion | Suj Accion | Suj Accion Objeto Lugar\n",
    "Suj -> Persona | Persona Otros Persona\n",
    "Accion -> V N | V Otros N | V V\n",
    "Persona -> 'abuela' | 'mujer' | 'pepe' | 'maría'\n",
    "Lugar -> Otros N\n",
    "Objeto -> Otros N Otros N\n",
    "V -> 'bebe' | 'fuma' | 'compra' | 'cocinan' | 'ha' | 'robado' | V V\n",
    "N -> 'vodka' | 'porros' | 'coche' | 'brownies' | 'huevo' | 'avestruz' | 'zoo'\n",
    "Otros -> 'y' | 'la' | 'un' | 'de' | 'del'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "22e7f178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  S                                  \n",
      "    ______________________________|___________________________        \n",
      "  Suj       Accion              Objeto                      Lugar    \n",
      "   |      ____|______        _____|_____________         _____|____   \n",
      "Persona  V           V    Otros   N    Otros    N     Otros        N \n",
      "   |     |           |      |     |      |      |       |          |  \n",
      " maría   ha        robado   un  huevo    de  avestruz  del        zoo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammar6)\n",
    "\n",
    "for tree in parsear(tokens6_min):\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8788f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
