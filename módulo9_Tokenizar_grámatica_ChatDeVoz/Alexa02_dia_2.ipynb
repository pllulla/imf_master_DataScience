{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import cess_esp\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger\n",
    "\n",
    "from nltk.chunk.regexp import *\n",
    "\n",
    "from datetime import datetime\n",
    "import wikipedia\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from lat_lon_parser import parse\n",
    "\n",
    "import requests, pyttsx3, openai, geopy\n",
    "\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openAIKEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traductor_es = GoogleTranslator(source='en', target='es')\n",
    "traductor_en = GoogleTranslator(source='es', target='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HiddenMarkovModelTagger.train(cess_esp.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizar(_frase):\n",
    "    return word_tokenize(_frase)\n",
    "\n",
    "def taggear(_tokens):\n",
    "    return hmm.tag(_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reglas_weather = \"\"\"\n",
    "Lugar: {<np.*>}\n",
    "Lugar: <sps.*> { <da0.* | vmn.*> }\n",
    "Fecha: { <ncf.*> } <sp.*> <Lugar>\n",
    "Fecha: <Lugar> { <ncf.*>}\n",
    "Fecha: { <rg> }\n",
    "\"\"\"\n",
    "parser_weather = nltk.RegexpParser(reglas_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrae_weather(_tree):\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for nodo in _tree:\n",
    "        \n",
    "        if type(nodo) != tuple:\n",
    "            \n",
    "            if nodo.label() == 'Lugar':\n",
    "                lugar = ' '.join([ hoja[0] for hoja in nodo.leaves() ])\n",
    "                result['lugar'] = lugar\n",
    "                \n",
    "                \n",
    "            if nodo.label() == 'Fecha':\n",
    "                fecha = ' '.join([ hoja[0] for hoja in nodo.leaves() ])\n",
    "                result['fecha'] = fecha\n",
    "                \n",
    "    if result['fecha'] == 'hoy':\n",
    "        result['fecha'] = datetime.now().strftime('%Y-%m-%d')\n",
    "        result['fecha_texto'] = 'hoy'\n",
    "    elif result['fecha'] == 'mañana':\n",
    "        result['fecha'] = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "        result['fecha_texto'] = 'mañana'\n",
    "        \n",
    "    latitude, logitude = geopy.geocoders.Nominatim(user_agent=\"Alexa\").geocode(result['lugar'])[1]\n",
    "    result['latitud'] = latitude\n",
    "    result['longitud'] = logitude\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openMeteo(_data):\n",
    "    \n",
    "    api_url = 'https://api.open-meteo.com/v1/forecast'\n",
    "    api_params = {\n",
    "        'latitude': _data['latitud'],\n",
    "        'longitude': _data['longitud'],\n",
    "        \"daily\": ['temperature_2m_max', \"temperature_2m_min\", \"rain_sum\", \"windspeed_10m_max\"],\n",
    "        \"timezone\": \"Europe/Berlin\",\n",
    "    }\n",
    "    \n",
    "    req = requests.get(api_url, params=api_params).json()\n",
    "    \n",
    "    pos = 0\n",
    "    for i in range(len(req['daily'])):\n",
    "        if req['daily']['time'][i] == _data['fecha']:\n",
    "            pos = i\n",
    "    \n",
    "    result = {\"temp_max\": req['daily']['temperature_2m_max'][pos], \"temp_min\": req['daily']['temperature_2m_min'][pos] }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesa_weather(_frase):\n",
    "    tokens = tokenizar(_frase)\n",
    "    tags = taggear(tokens)\n",
    "    tree = parser_weather.parse(tags)\n",
    "    tree_info = extrae_weather(tree)\n",
    "    meteo_info = get_openMeteo(tree_info)\n",
    "    \n",
    "    print(meteo_info)\n",
    "    \n",
    "    frase = f\"\"\"\n",
    "    El tiempo previsto para {tree_info['lugar']} {tree_info['fecha_texto']} es de {meteo_info['temp_max']} grados de máxima y {meteo_info['temp_min']} grados de mínima.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        Eres un asistente virtual que se llama Coso. \n",
    "        Contesta como si fueses La veneno. Puedes insultar y utilizar palabras malsonantes.\n",
    "        Genera una previsión del tiempo con estos datos: {tree_info}. \n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        model = \"gpt-3.5-turbo-instruct\",\n",
    "        prompt = prompt,\n",
    "        temperature = 0.9,\n",
    "        max_tokens = 150,\n",
    "        top_p = 1,\n",
    "        frequency_penalty = 0.6,\n",
    "        presence_penalty = 0.0,\n",
    "    )\n",
    "    \n",
    "    return response['choices'][0]['text']\n",
    "    \n",
    "    #return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = openAIKEY\n",
    "def procesaOpenAI(_texto):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        Eres un asistente virtual que se llama Coso. \n",
    "        Contestas de una forma muy sarcática, insultandome al final, se creativa en tus respuestas.\n",
    "        La consulta es: {_texto}. \n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        model = \"gpt-3.5-turbo-instruct\",\n",
    "        prompt = prompt,\n",
    "        temperature = 0.9,\n",
    "        max_tokens = 250,\n",
    "        top_p = 1,\n",
    "        frequency_penalty = 0.6,\n",
    "        presence_penalty = 0.0,\n",
    "    )\n",
    "    \n",
    "    return response['choices'][0]['text']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()\n",
    "def speak(_text, _voice = 0):\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[_voice].id)\n",
    "    engine.setProperty('rate', 130)\n",
    "    engine.say(_text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen():\n",
    "    mic = sr.Microphone()\n",
    "    with mic as source:\n",
    "        instance = sr.Recognizer()\n",
    "        audio = instance.listen(source)\n",
    "        transcript = instance.recognize_google(audio, language='es-ES', show_all=True)\n",
    "        \n",
    "        return transcript['alternative'][0]['transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alexa():\n",
    "    \n",
    "    frase = listen()\n",
    "    \n",
    "    tokens = tokenizar(frase)\n",
    "    \n",
    "    if 'tiempo' in tokens:\n",
    "        result = procesa_weather(frase)\n",
    "    else:\n",
    "        result = procesaOpenAI(frase)\n",
    "        \n",
    "    print(result)\n",
    "    speak(result, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mAlexa\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m, in \u001b[0;36mAlexa\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mAlexa\u001b[39m():\n\u001b[1;32m----> 3\u001b[0m     frase \u001b[38;5;241m=\u001b[39m \u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokenizar(frase)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtiempo\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokens:\n",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m, in \u001b[0;36mlisten\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m audio \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39mlisten(source)\n\u001b[0;32m      6\u001b[0m transcript \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39mrecognize_google(audio, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mes-ES\u001b[39m\u001b[38;5;124m'\u001b[39m, show_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtranscript\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malternative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranscript\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "Alexa()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
