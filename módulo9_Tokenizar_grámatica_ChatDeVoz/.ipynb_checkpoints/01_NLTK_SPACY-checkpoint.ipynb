{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d319cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#Es la libreria que nos ayudara a trabajar con textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizar, dividir el texto en partes pequeñas, por palabras normalmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6452d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frase = \"si esto es verdad, todo el tema de la tarta es una mentira\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd82d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9983c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a2948",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_de_palabras = len(tokens)\n",
    "print(\"Número de palabras:\", numero_de_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51efde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e5bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stopwords(_tokens):\n",
    "    clean_tokens = _tokens\n",
    "    for  token in _tokens:\n",
    "        if token in stopwords.words('spanish'):\n",
    "            clean_tokens.remove(token)\n",
    "            \n",
    "    clean_tokens = [word.lower() for word in clean_tokens if word.isalpha()]\n",
    "\n",
    "    return clean_tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39114d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = delete_stopwords(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b86fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(delete_stopwords(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1417323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lematización y Steamming, dejar las palabras en su raíz pura (primitiva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad2e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3339353",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_steamer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09798400",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_tokens = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in clean_tokens:\n",
    "    stem_tokens.append(spanish_steamer.stem(token))\n",
    "    \n",
    "print(stem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8bf9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U pip setuptools wheel\n",
    "#!pip install -U spacypyth\n",
    "#!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135bae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a111ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_tokens = []\n",
    "\n",
    "for token in nlp(' '.join(clean_tokens)):\n",
    "    len_tokens.append(token.lemma_)\n",
    "\n",
    "print(len_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a73c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Densidad de palabras\n",
    "# Detector de SPAM de un mail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c643ce",
   "metadata": {},
   "source": [
    "La densidad de cada palabra se calcula como la frecuencia de esa palabra dividida por el número total de palabras en el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed6889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "frase = \"si esto es verdad, todo el tema de la tarta es una mentira\"\n",
    "tokens = nltk.word_tokenize(frase)\n",
    "total_palabras = len(tokens)\n",
    "\n",
    "# Contando la frecuencia de cada palabra\n",
    "frecuencia_palabras = Counter(tokens)\n",
    "\n",
    "# Calculando la densidad de cada palabra\n",
    "densidad_palabras = {palabra: frecuencia / total_palabras for palabra, frecuencia in frecuencia_palabras.items()}\n",
    "\n",
    "print(densidad_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33478d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Definiendo la función para eliminar stopwords\n",
    "def delete_stopwords(_tokens):\n",
    "    stopwords_espanol = set(stopwords.words('spanish'))\n",
    "    clean_tokens = [token.lower() for token in _tokens if token.lower() not in stopwords_espanol and token.isalpha()]\n",
    "    return clean_tokens\n",
    "\n",
    "# Frase de ejemplo\n",
    "frase = \"\"\"Varios centenares de personas se reúnen en la calle Ferraz contra la investidura de Sánchez\n",
    "Varios centenares de manifestantes se reúnen ya en las inmediaciones de la sede del PSOE en Madrid para protestar contra la amnistía y la investidura del líder socialista, Pedro Sánchez, que renovará el cargo de presidente de Gobierno tras haber conseguido por mayoría absoluta ser investido este jueves en el Congreso de los Diputados. \n",
    "Desde el comienzo de la concentración, los asistentes no han cesado de entonar los cánticos más repetidos desde que comenzaran las protestas el pasado 3 de noviembre: \"Pedro Sánchez, hijo de puta\", \"Arderá Ferraz, antes o después\", \"No es un presidente, es un delincuente\".  Eso sí, también hay novedades en el repertorio: \"El que no bote, secreta es\", gritan jóvenes y mayores mientras saltan.\n",
    "Entre los manifestantes comentan las 12 detenciones que se produjeron en la protesta de este miércoles, y hablan también sobre la arremetida que la Unidad de Intervención Policial (UIP) llevó a cabo para despejar la zona. Otros grupos de amigos critican el saludo del líder del PP,  Alberto Núñez Feijóo, a Sánchez tras la votación en el Congreso de los Diputados: \"¿Pero cómo le va a dar la mano?\", dice, airado, un hombre junto a la valla que separa a los manifestantes de la Policía. \n",
    "En el cruce de la calle de Marqués de Urquijo con calle de la Princesa, un dispositivo de la Policía cachea a los asistentes. A pocos metros, cinco vendedores se apresuran para ofrecer banderas de España de todos los tamaños: \"A defender España\", le dicen a los recién llegados a la convocatoria.\"\"\"\n",
    "\n",
    "tokens = nltk.word_tokenize(frase)\n",
    "\n",
    "# Eliminando stopwords y signos de puntuación\n",
    "tokens_filtrados = delete_stopwords(tokens)\n",
    "\n",
    "# Contando la frecuencia de las palabras filtradas\n",
    "frecuencia_palabras_filtradas = Counter(tokens_filtrados)\n",
    "total_palabras_filtradas = len(tokens_filtrados)\n",
    "\n",
    "# Creando un DataFrame\n",
    "df_filtrado = pd.DataFrame(frecuencia_palabras_filtradas.items(), columns=['Palabra', 'Frecuencia'])\n",
    "df_filtrado['Densidad'] = df_filtrado['Frecuencia'] / total_palabras_filtradas\n",
    "\n",
    "df_filtrado_ordenado = df_filtrado.sort_values(by='Frecuencia', ascending=False)\n",
    "df_filtrado_ordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "# Cargar el modelo de spaCy para procesamiento en inglés\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Lista de palabras clave comunes en SPAM\n",
    "palabras_clave_spam = ['oferta', 'gratis', 'promoción', 'suscribir', 'descuento']\n",
    "\n",
    "# Ejemplo de correo electrónico\n",
    "correo = \"¡Gran oferta! Obtén un descuento del 50% al suscribirte hoy.\"\n",
    "\n",
    "# Procesamiento del correo electrónico\n",
    "correo_procesado = nlp(correo.lower())\n",
    "\n",
    "# Eliminar stopwords y lematizar\n",
    "tokens_filtrados = [token.lemma_ for token in correo_procesado if token.text not in stopwords.words('english')]\n",
    "\n",
    "# Detector de SPAM\n",
    "es_spam = any(palabra in tokens_filtrados for palabra in palabras_clave_spam)\n",
    "\n",
    "print(\"Es SPAM:\" if es_spam else \"No es SPAM\", correo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6021bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
