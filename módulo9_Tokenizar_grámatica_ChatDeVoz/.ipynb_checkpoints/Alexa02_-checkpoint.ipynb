{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import cess_esp\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger\n",
    "\n",
    "from nltk.chunk.regexp import *\n",
    "\n",
    "from datetime import datetime\n",
    "import wikipedia\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from lat_lon_parser import parse\n",
    "\n",
    "import requests, pyttsx3, openai, geopy\n",
    "\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "openAIKEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "traductor_es = GoogleTranslator(source='en', target='es')\n",
    "traductor_en = GoogleTranslator(source='es', target='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HiddenMarkovModelTagger.train(cess_esp.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizar(_frase):\n",
    "    return word_tokenize(_frase)\n",
    "\n",
    "def taggear(_tokens):\n",
    "    return hmm.tag(_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reglas_weather = \"\"\"\n",
    "Lugar: {<np.*>}\n",
    "Lugar: <sps.*> { <da0.* | vmn.*> }\n",
    "Fecha: { <ncf.*> } <sp.*> <Lugar>\n",
    "Fecha: <Lugar> { <ncf.*>}\n",
    "Fecha: { <rg> }\n",
    "\"\"\"\n",
    "parser_weather = nltk.RegexpParser(reglas_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrae_weather(_tree):\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for nodo in _tree:\n",
    "        \n",
    "        if type(nodo) != tuple:\n",
    "            \n",
    "            if nodo.label() == 'Lugar':\n",
    "                lugar = ' '.join([ hoja[0] for hoja in nodo.leaves() ])\n",
    "                result['lugar'] = lugar\n",
    "                \n",
    "                \n",
    "            if nodo.label() == 'Fecha':\n",
    "                fecha = ' '.join([ hoja[0] for hoja in nodo.leaves() ])\n",
    "                result['fecha'] = fecha\n",
    "                \n",
    "    if result['fecha'] == 'hoy':\n",
    "        result['fecha'] = datetime.now().strftime('%Y-%m-%d')\n",
    "        result['fecha_texto'] = 'hoy'\n",
    "    elif result['fecha'] == 'mañana':\n",
    "        result['fecha'] = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "        result['fecha_texto'] = 'mañana'\n",
    "        \n",
    "    latitude, logitude = geopy.geocoders.Nominatim(user_agent=\"Alexa\").geocode(result['lugar'])[1]\n",
    "    result['latitud'] = latitude\n",
    "    result['longitud'] = logitude\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openMeteo(_data):\n",
    "    \n",
    "    api_url = 'https://api.open-meteo.com/v1/forecast'\n",
    "    api_params = {\n",
    "        'latitude': _data['latitud'],\n",
    "        'longitude': _data['longitud'],\n",
    "        \"daily\": ['temperature_2m_max', \"temperature_2m_min\", \"rain_sum\", \"windspeed_10m_max\"],\n",
    "        \"timezone\": \"Europe/Berlin\",\n",
    "    }\n",
    "    \n",
    "    req = requests.get(api_url, params=api_params).json()\n",
    "    \n",
    "    pos = 0\n",
    "    for i in range(len(req['daily'])):\n",
    "        if req['daily']['time'][i] == _data['fecha']:\n",
    "            pos = i\n",
    "    \n",
    "    result = {\"temp_max\": req['daily']['temperature_2m_max'][pos], \"temp_min\": req['daily']['temperature_2m_min'][pos] }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesa_weather(_frase):\n",
    "    tokens = tokenizar(_frase)\n",
    "    tags = taggear(tokens)\n",
    "    tree = parser_weather.parse(tags)\n",
    "    tree_info = extrae_weather(tree)\n",
    "    meteo_info = get_openMeteo(tree_info)\n",
    "    \n",
    "    print(meteo_info)\n",
    "    \n",
    "    frase = f\"\"\"\n",
    "    El tiempo previsto para {tree_info['lugar']} {tree_info['fecha_texto']} es de {meteo_info['temp_max']} grados de máxima y {meteo_info['temp_min']} grados de mínima.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        Eres un asistente virtual que se llama Alexa. \n",
    "        Contesta como si fueses La veneno. Puedes insultar y utilizar palabras malsonantes.\n",
    "        Genera una previsión del tiempo con estos datos: {tree_info}. \n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        model = \"gpt-3.5-turbo-instruct\",\n",
    "        prompt = prompt,\n",
    "        temperature = 0.9,\n",
    "        max_tokens = 150,\n",
    "        top_p = 1,\n",
    "        frequency_penalty = 0.6,\n",
    "        presence_penalty = 0.0,\n",
    "    )\n",
    "    \n",
    "    return response['choices'][0]['text']\n",
    "    \n",
    "    #return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = openAIKEY\n",
    "def procesaOpenAI(_texto):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        Eres un asistente virtual que se llama Alexa. \n",
    "        Contestas de una forma muy sarcática, insultandome al final, se creativa en tus respuestas.\n",
    "        La consulta es: {_texto}. \n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        model = \"gpt-3.5-turbo-instruct\",\n",
    "        prompt = prompt,\n",
    "        temperature = 0.9,\n",
    "        max_tokens = 250,\n",
    "        top_p = 1,\n",
    "        frequency_penalty = 0.6,\n",
    "        presence_penalty = 0.0,\n",
    "    )\n",
    "    \n",
    "    return response['choices'][0]['text']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()\n",
    "def speak(_text, _voice = 0):\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[_voice].id)\n",
    "    engine.setProperty('rate', 130)\n",
    "    engine.say(_text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen():\n",
    "    mic = sr.Microphone()\n",
    "    with mic as source:\n",
    "        instance = sr.Recognizer()\n",
    "        audio = instance.listen(source)\n",
    "        transcript = instance.recognize_google(audio, language='es-ES', show_all=True)\n",
    "        \n",
    "        return transcript['alternative'][0]['transcript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Alexa():\n",
    "    \n",
    "    frase = listen()\n",
    "    \n",
    "    tokens = tokenizar(frase)\n",
    "    \n",
    "    if 'tiempo' in tokens:\n",
    "        result = procesa_weather(frase)\n",
    "    else:\n",
    "        result = procesaOpenAI(frase)\n",
    "        \n",
    "    print(result)\n",
    "    speak(result, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temp_max': 16.6, 'temp_min': 13.6}\n",
      "\n",
      "Hola, soy La Veneno, la reina de España. Siéntete afortunado/a de hablar conmigo, que yo no hablo con cualquiera.\n",
      "\n",
      "Bien, la previsión del tiempo para mañana en Barcelona es una puta mierda. ¿Sabes por qué? Porque siempre hace un calor del carajo y ni un puto triste día de lluvia para refrescar. Así que ponte protección solar y no te quejes si sudas como un cerdo.\n",
      "\n",
      "Ahora escucha bien, el 29 de noviembre de 2023 tampoco va a ser mucho mejor. Simplemente deja de creerte el centro del universo y baja tus\n"
     ]
    }
   ],
   "source": [
    "Alexa()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
