{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faeb271b",
   "metadata": {},
   "source": [
    "# Pinecone - Creando un asistente conversacional\n",
    "\n",
    "### Arquitectura RAG\n",
    "\n",
    "1. [Introducción](#intro)\n",
    "2. [LangChain](#langchain)\n",
    "3. [Embeddings](#embeddings)\n",
    "4. [Carga de los Embeddings en Pinecone](#persist)\n",
    "5. [Integración con OpenAI y generación de prompts](#openai)\n",
    "\n",
    "## Introducción <a name=\"intro\"></a>\n",
    "\n",
    "El propósito general de este notebook es generar un asistente conversacional basado en la arquitectura RAG (_Retrieval Augmented Generation_), es decir, nosotros dispondremos de unos documentos PDFs que serán nuestra base de conocimiento (_knowledgebase_) almacenados como Embeddings dentro de Pinecone, posteriormente, a través de LangChain conectaremos los modelos GPT para dotar al sistema de la capacidad de lanzar querys en forma de procesamiento del lenguaje natural que este, se conecte con la Embedding del usuario a la BD Vectorial y, sea capaz de devolver información detallada sobre nuestros propios documentos mediante IA Generativa con los modelos GPT\n",
    "\n",
    "## LangChain <a name=\"langchain\"></a>\n",
    "\n",
    "LangChain (https://python.langchain.com/docs/get_started/introduction) se trata de una iniciativa Open Source que nos permite aobrdar uno de los problemas más recurrentes cuando trabajamos con LLMs que no es ni más ni menos que \"poder entablar una conversación\".\n",
    "\n",
    "Como tal, podemos hacer peticiones a un modelo GPT una sola vez, este, sin problemas nos proveerá de una respuesta, pero, ¿Cómo podemos dotar a un sistema de la capacidad de enlazar (encadenar) una conversación? ahí es donde surge LangChain.\n",
    "\n",
    "__LangChain__ es un marco para desarrollar aplicaciones basadas en modelos del lenguaje (únicamente se especializa en NLP), gracias a LangChain se consigue que:\n",
    "+ Se creen modelos que sean _conscientes_ del contexto de una conversación.\n",
    "+ Otorgar a un modelo Large Language Model la capacidad de razonar.\n",
    "\n",
    "Para instalar LangChain en Python haremos:\n",
    "\n",
    "```python\n",
    "!pip install langchain\n",
    "```\n",
    "\n",
    "Además de encadenar conversaciones LangChain tiene una funcionalidad muy interesante que es la de leer archivos para su posterior procesamiento, no solo PDFs e incluso funciones para aplicar Transformers a dichos documentos. https://python.langchain.com/docs/modules/data_connection/\n",
    "\n",
    "La función `document_loaders` https://python.langchain.com/docs/modules/data_connection/document_loaders/ tiene la capacidad de cargar los siguientes tipos de archivos:\n",
    "+ CSV\n",
    "+ Directorios\n",
    "+ PDF\n",
    "+ Markdown y texto\n",
    "+ HTML\n",
    "+ JSON\n",
    "\n",
    "Importamos un archivo PDF, previamente necesitamos instalar una dependencia\n",
    "```python\n",
    "!pip install pypdf\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad2e1590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='© 2013 Korean Society of Nursing Science  www.kan.or.kr  |  ISSN 2005-3673INTRODUCTION\\nMultivariable methods of statistical analysis commonly appear in \\ngeneral health science literature (Bagley, White, & Golomb, 2001). The \\nterms “multivariate analysis” and “multivariable analysis” are often used \\ninterchangeably in the literature. In the strict sense, multivariate analysis \\nrefers to simultaneously predicting multiple outcomes and multivariable \\nanalysis uses multiple variables to predict a single outcome (Katz, 1999). \\nThe multivariable methods explore a relation between two or more \\npredictor (independent) variables and one outcome (dependent) vari-\\nable. The model describing the relationship expresses the predicted value \\nof the outcome variable as a sum of products, each product formed by \\nmultiplying the value and coefficient of the independent variable. The \\ncoefficients are obtained as the best mathematical fit for the specified \\nmodel. A coeﬃcient indicates the impact of each independent variable \\non the outcome variable adjusting for all other independent variables. The model serves two purposes: (1) it can predict the value of the depen-\\ndent variable for new values of the independent variables, and (2) it can \\nhelp describe the relative contribution of each independent variable to \\nthe dependent variable, controlling for the inﬂuences of the other inde-\\npendent variables. The four main multivariable methods used in health \\nscience are linear regression, logistic regression, discriminant analysis, \\nand proportional hazard regression.\\nThe four multivariable methods have many mathematical similarities \\nbut differ in the expression and format of the outcome variable. In linear \\nregression, the outcome variable is a continuous quantity, such as blood \\npressure. In logistic regression, the outcome variable is usually a binary \\nevent, such as alive versus dead, or case versus control. In discriminant \\nanalysis, the outcome variable is a category or group to which a subject \\nbelongs. For only two categories, discriminant analysis produces results \\nsimilar to logistic regression. In proportional hazards regression, the out-\\ncome variable is the duration of time to the occurrence of a binary “fail-An Introduction to Logistic Regression: From Basic Concepts \\nto Interpretation with Particular Attention to Nursing Domain    \\nPark, Hyeoun -Ae\\nCollege of Nursing and System Biomedical Informatics National Core Research Center, Seoul National University, Seoul, KoreaJ Korean Acad Nurs  Vol.43  No.2, 154 -164\\nJ Korean Acad Nurs  Vol.43  No.2 April 2013 \\x08 http://dx.doi.org/10.4040/jkan.2013.43.2.154\\nPurpose: The purpose of this article is twofold: 1) introducing logistic regression (LR), a multivariable method for modeling the \\nrelationship between multiple independent variables and a categorical dependent variable, and 2) examining use and reporting of LR in the nursing literature. Methods: Text books on LR and research articles employing LR as main statistical analysis were \\nreviewed. Twenty\\n-three articles published between 2010 and 2011 in the Journal of Korean Academy of Nursing were analyzed \\nfor proper use and reporting of LR models. Results: Logistic regression from basic concepts such as odds, odds ratio, logit \\ntransformation and logistic curve, assumption, fitting, reporting and interpreting to cautions were presented. Substantial short-\\ncomings were found in both use of LR and reporting of results. For many studies, sample size was not sufficiently large to call \\ninto question the accuracy of the regression model. Additionally, only one study reported validation analysis. Conclusion: Nurs-\\ning researchers need to pay greater attention to guidelines concerning the use and reporting of LR models.\\nKey words:  Logit function, Maximum likelihood estimation, Odds, Odds ratio, Wald test\\nAddress reprint requests to : Park, Hyeoun -Ae\\nCollege of Nursing, Seoul National University, 103 Daehak-ro, Jongno-gu, Seoul 110-799, Korea\\nTel: +82-10-3786-3284, Fax: +82-2-765-4103, E-mail: hapark@snu.ac.kr \\nReceived: March 19, 2013 Accepted: April 2, 2013', metadata={'source': 'An_Introduction_to_Logistic_Regression_From_Basic_.pdf', 'page': 0}),\n",
       " Document(page_content='155\\nhttp://dx.doi.org/10.4040/jkan.2013.43.2.154 www.kan.or.krAn\\x08Introduction\\x08to\\x08Logistic\\x08Regression:\\x08From\\x08Basic\\x08Concepts\\x08to\\x08Interpretation\\x08with\\x08Particular\\x08Attention\\x08to\\x08Nursing\\x08Domain\\x08\\x08\\x08\\x08\\nure” event (for example, death) during a follow-up period of observation.  \\nThe logistic regression is the most popular multivariable method used \\nin health science (Tetrault, Sauler, Wells, & Concato, 2008). In this article \\nlogistic regression (LR) will be presented from basic concepts to inter-\\npretation. In addition, the use of LR in nursing literature will be exam-\\nined by comparing the actual use of LR with published criteria for use \\nand reporting.\\nCONCEPTS RELATED TO LOGISTIC REGRESSION \\nLogistic regression sometimes called the logistic model or logit model, \\nanalyzes the relationship between multiple independent variables and a \\ncategorical dependent variable, and estimates the probability of occur-\\nrence of an event by fitting data to a logistic curve. There are two models \\nof logistic regression, binary logistic regression and multinomial logistic \\nregression. Binary logistic regression is typically used when the depen-\\ndent variable is dichotomous and the independent variables are either \\ncontinuous or categorical. When the dependent variable is not dichoto-\\nmous and is comprised of more than two categories, a multinomial lo-\\ngistic regression can be employed. \\nAs an illustrative example, consider how coronary heart disease (CHD) \\ncan be predicted by the level of serum cholesterol. The probability of CHD \\nincreases with the serum cholesterol level. However, the relationship be-\\ntween CHD and serum cholesterol is nonlinear and the probability of \\nCHD changes very little at the low or high extremes of serum cholesterol. \\nThis pattern is typical because probabilities cannot lie outside the range \\nfrom 0 to 1. The relationship can be described as an ‘S’-shaped curve. The \\nlogistic model is popular because the logistic function, on which the logis-\\ntic regression model is based, provides estimates in the range 0 to 1 and an \\nappealing S-shaped description of the combined effect of several risk fac-\\ntors on the risk for an event (Kleinbaum & Klein, 2010). \\n1. Odds \\nOdds of an event are the ratio of the probability that an event will oc-\\ncur to the probability that it will not occur. If the probability of an event \\noccurring is p, the probability of the event not occurring is (1-p). Then \\nthe corresponding odds is a value given by \\nodds of {Event}=p\\n1-pSince logistic regression calculates the probability of an event occur-\\nring over the probability of an event not occurring, the impact of inde-\\npendent variables is usually explained in terms of odds. With logistic re-\\ngression the mean of the response variable p in terms of an explanatory \\nvariable x is modeled relating p and x through the equation p=α+βx. \\nUnfortunately, this is not a good model because extreme values of x will \\ngive values of α+βx that does not fall between 0 and 1. The logistic regres-\\nsion solution to this problem is to transform the odds using the natural \\nlogarithm (Peng, Lee &  Ingersoll, 2002). With logistic regression we \\nmodel the natural log odds as a linear function of the explanatory variable:\\nlogit (y)=ln (odds)=ln                =a + βχ                   (1)p\\n1-p(               )\\nwhere p is the probability of interested outcome and x is the explanatory \\nvariable. The parameters of the logistic regression are α and β. This is the \\nsimple logistic model.\\nTaking the antilog of equation (1) on both sides, one can derive an \\nequation for the prediction of the probability of the occurrence of inter-\\nested outcome as\\np=P (Y=interested outcome/X=χ, a speciﬁc vlaue)\\n    =                      =ea+βχ\\n1 + ea+βχ1\\n1 + e-(a+βχ)\\nExtending the logic of the simple logistic regression to multiple pre-\\ndictors, one may construct a complex logistic regression as \\nlogit (y)=ln                =a + β1 χ1 + ... +βk χk p\\n1-p(               )\\nTherefore, \\np=P (Y=interested outcome/X1=χ1, ... Xk=χk)\\n    =                          =ea+β1χ1 + ... +βkχk\\n1 + ea+β1χ1 + ... +βkχk1\\n1 + e-(a+β1χ1 + ... +βkχk)\\n2. Odds ratio\\nThe odds ratio (OR) is a comparative measure of two odds relative to \\ndifferent events. For two events A and B, the corresponding odds of A \\noccurring relative to B occurring is \\nodds ratio {A vs.B}=       =  pA⁄ (1-pA)\\npB⁄ (1-pB)odds {A}\\nodds {B}\\nAn OR is a measure of association between an exposure and an out-', metadata={'source': 'An_Introduction_to_Logistic_Regression_From_Basic_.pdf', 'page': 1}),\n",
       " Document(page_content='156\\nhttp://dx.doi.org/10.4040/jkan.2013.43.2.154 www.kan.or.krPark,\\x08Hyeoun-Ae\\ny=     =ex\\n1 + ex1\\n1 + e-x\\nwhich is graphed in Figure 1. \\nTo provide ﬂexibility, the logistic function can be extended to the form \\ny=                      =ea+βχ\\n1 + ea+βχ1\\n1 + e-(a+βχ)\\nwhere α and β determine the logistic intercept and slope. \\nLogistic regression fits α and β, the regression coefficients. Figure 1 \\nshows logistic function when α and β are 0 and 1, respectively. The logis-\\ntic or logit function is used to transform an ‘S’-shaped curve into an ap-\\nproximately straight line and to change the range of the proportion from \\n0 – 1 to -∞ -+∞ as\\np\\n1-p(               ) logit (y)=ln (odds)= ln                  =α + βχ \\nwhere p is the probability of interested outcome, α is the intercept pa-\\nrameter, β is a regression coeﬃcient, and χ is a predictor. \\nASSUMPTIONS OF LOGISTIC REGRESSION\\nLogistic regression does not require many of the principle assump-\\ntions of linear regression models that are based on ordinary least squares \\nmethod–particularly regarding linearity of relationship between the de-\\npendent and independent variables, normality of the error distribution, \\nhomoscedasticity of the errors, and measurement level of the indepen-\\ndent variables. Logistic regression can handle non-linear relationships \\nbetween the dependent and independent variables, because it applies a \\nnon-linear log transformation of the linear regression. The error terms come. The OR represents the odds that an outcome (e.g. disease or disor-\\nder) will occur given a particular exposure (e.g. health behavior, medical \\nhistory), compared to the odds of the outcome occurring in the absence \\nof that exposure. \\nWhen a logistic regression is calculated, the regression coeﬃcient (b1) is \\nthe estimated increase in the logged odds of the outcome per unit increase \\nin the value of the independent variable. In other words, the exponential \\nfunction of the regression coeﬃcient (eb1) is the OR associated with a one-\\nunit increase in the independent variable. The OR can also be used to de-\\ntermine whether a particular exposure is a risk factor for a particular out-\\ncome, and to compare the magnitude of various risk factors for that out-\\ncome. OR=1 indicates exposure does not affect odds of outcome. OR>1 \\nindicates exposure associated with higher odds of outcome. OR<1 indi-\\ncates exposure associated with lower odds of outcome. For example, the \\nvariable smoking is coded as 0 (=no smoking) and 1 (=smoking), and \\nthe odds ratio for this variable is 3.2. Then, the odds for a positive outcome \\nin smoking cases are 3.2 times higher than in non-smoking cases.\\nLogistic regression is one way to generalize the OR beyond two binary \\nvariables (Peng & So, 2002). Suppose we have a binary response variable Y \\nand a binary predictor variable X, and in addition we have other predictor \\nvariables Z1, ..., Zk that may or may not be binary. If we use multiple logistic \\nregression to regress Y on X, Z1, ..., Zk, then the estimated coeﬃcient βxfor \\nX is related to a conditional OR. Specifically, at the population level\\neβx=P (Y=1│X=1, Z1, …, Zk) / P (Y=0│X=1, Z1, …, Zk)\\nP (Y=1│X=0, Z1, …, Zk) / P (Y=0│X=0, Z1, …, Zk)\\nso eβxis an estimate of this conditional odds ratio. The interpretation of \\neβxis as an estimate of the OR between Y and X when the values of Z1, ..., \\nZk are held fixed. \\n3. The logistic curve \\nLogistic regression is a method for fitting a regression curve, y =f(x), \\nwhen y consists of binary coded (0, 1--failure, success) data. When the \\nresponse is a binary (dichotomous) variable and x is numerical, logistic \\nregression fits a logistic curve to the relationship between x and y. Logis-\\ntic curve is an S-shaped or sigmoid curve, often used to model popula-\\ntion growth (Eberhardt & Breiwick, 2012). A logistic curve starts with \\nslow, linear growth, followed by exponential growth, which then slows \\nagain to a stable rate.\\nA simple logistic function is defined by the formula\\nexp(x)/(1 +exp(x))\\n-6     -4      -2       0       2       4       6\\nx0.8 0.4 0.0\\nFigure 1. Graph of logistic curve where α=0 and β=1.', metadata={'source': 'An_Introduction_to_Logistic_Regression_From_Basic_.pdf', 'page': 2}),\n",
       " Document(page_content='157\\nhttp://dx.doi.org/10.4040/jkan.2013.43.2.154 www.kan.or.krAn\\x08Introduction\\x08to\\x08Logistic\\x08Regression:\\x08From\\x08Basic\\x08Concepts\\x08to\\x08Interpretation\\x08with\\x08Particular\\x08Attention\\x08to\\x08Nursing\\x08Domain\\x08\\x08\\x08\\x08\\n(the residuals) do not need to be multivariate normally distributed–al-\\nthough multivariate normality yields a more stable solution. The vari-\\nance of errors can be heteroscedastic for each level of the independent \\nvariables. Logistic regression can handle not only continuous data but \\nalso discrete data as independent variables.  \\nHowever, some other assumptions still apply (Bewick, Cheek, & Ball, \\n2005; Peng & So, 2002): First, logistic regression requires the dependent \\nvariable to be discrete mostly dichotomous. Second, since logistic regres-\\nsion estimates the probability of the event occurring (P(Y=1)), it is neces-\\nsary to code the dependent variable accordingly. That is the desired out-\\ncome should be coded to be 1. Third, the model should be fitted cor-\\nrectly. It should not be over fitted with the meaningless variables in-\\ncluded. Also it should not be under fitted with meaningful variable not \\nincluded. Fourth, logistic regression requires each observation to be in-\\ndependent. Also the model should have little or no multicollinear-\\nity. That is, independent variables are not linear functions of each other. \\nFifth, whilst logistic regression does not require a linear relationship be-\\ntween the dependent and independent variables, it requires that the in-\\ndependent variables are linearly related to the log odds of an event. Lastly, \\nlogistic regression requires large sample sizes because maximum likeli-\\nhood estimates are less powerful than ordinary least squares used for es-\\ntimating the unknown parameters in a linear regression model. \\nSTUDY DESIGN OF LOGISTIC REGRESSION\\nLogistic regression model corresponds to data from either a cross-sec-\\ntional, prospective, or retrospective case-control study (Hsieh, Bloch & \\nLarsen, 1998). In the cross-sectional studies a random sample is taken \\nfrom a population, and outcome and explanatory variables are collected si-\\nmultaneously. The fitted probabilities from a logistic regression model are \\nthen estimates of proportions of an outcome in the underlying population. \\nIn the prospective studies, a set of subjects are selected and the ex-\\nplanatory variables are observed. Subjects are then followed over some \\nstandard period (e.g. a month or a year) or episode (hospital stay) to de-\\ntermine the response outcome. In this case, the fitted probabilities are \\nestimates of the probability of the response outcomes occurring. \\nIn the retrospective case-control studies, separate samples of case and \\ncontrol groups are first assembled and potential explanatory variables \\nare collected later often through their recollections. In this case the fitted \\nprobabilities do not have a direct interpretation since they are deter-\\nmined by the relative sample sizes for case and control groups. However, odds ratios can be estimated based on logistic regression.\\nSAMPLE SIZE FOR LOGISTIC REGRESSION\\nSample size calculation for logistic regression is a complicated prob-\\nlem, because there are so many factors involved in determining sample \\nsize such as statistical power, number of parameters to estimate, percent-\\nage of 1’s, effect size, and standard error. There are many researchers sug-\\ngesting different methods to calculate the required sample size for logis-\\ntic regression (Hosmer & Lemeshow, 2000; Hsieh et al., 1998). \\nHsieh et al. (1998) proposed a sample size formula for a simple logistic \\nregression with a continuous variable with a normal distribution:\\nn=(Z1-α⁄2+Z1-β)2\\nP1 (1-P1) β*2\\nwhere n is the required total sample size, β* is the effect size to be tested \\nthe null hypothesis H0 : β1=0 against the alternative H1 : β1=β*, where β*\\n≠0, P1 is the overall event rate at the mean of X, and Zu is the upper uth \\npercentiles of the standard normal distribution. \\nWhen the covariate is a binary variable, the sample size formula for \\nthe total sample size required for comparing two independent event \\nrates has the following form\\n(                                                                                            )\\nn=(P1-P2)2 (1-B)Z1-α⁄2                   +Z1-β     P1(1-P1)+P2(1-P2)P(1-P)\\nB(1-B)\\nB2\\nwhere P= (1-B)P1+BP2 is the overall event rate; B is the proportion of \\nthe sample with X=1; P1 and P2 are the event rates at X=0 and X=1, re-\\nspectively. \\nFor multiple logistic regression, Peduzzi , Concato, Kemper, Holford, & \\nFeinstein (1996) suggested a very simple guideline for a minimum number \\nof cases for logistic regression study. Let p be the smallest of the propor-\\ntions of negative or positive cases in the population and k the number of \\nindependent variables, then the minimum number of cases to include is:\\nN=10 k / p\\nFor example, if there are 5 explanatory variables to include in the \\nmodel and the proportion of positive cases in the population is 0.25 \\n(25%). The minimum number of cases required is\\nN=10 x 5 / 0.25=200\\nLong (1997) suggested that if the resulting number is less than 100 it \\nshould be increased to 100.  ', metadata={'source': 'An_Introduction_to_Logistic_Regression_From_Basic_.pdf', 'page': 3}),\n",
       " Document(page_content='158\\nhttp://dx.doi.org/10.4040/jkan.2013.43.2.154 www.kan.or.krPark,\\x08Hyeoun-Ae\\nFITTING THE LOGISTIC REGRESSION MODEL\\nAlthough logistic regression model, logit (y)=α+βχ looks similar to a \\nsimple linear regression model, the underlying distribution is binomial \\nand the parameters, α and β cannot be estimated in the same way as for \\nsimple linear regression. Instead, the parameters are usually estimated \\nusing the method of maximum likelihood of observing the sample val-\\nues (Menard, 2001). Maximum likelihood will provide values of α and β\\nwhich maximize the probability of obtaining the data set. It requires it-\\nerative computing with computer software.\\nThe likelihood function is used to estimate the probability of observing \\nthe data, given the unknown parameters (α and β). A “likelihood” is a prob-\\nability that the observed values of the dependent variable may be predicted \\nfrom the observed values of the independent variables. The likelihood var-\\nies from 0 to 1 like any other probabilities. Practically, it is easier to work \\nwith the logarithm of the likelihood function. This function is known as \\nthe log-likelihood. Log-likelihood will be used for inference testing when \\ncomparing several models. The log likelihood varies from 0 to -∞ (it is neg-\\native because the natural log of any number less than 1 is negative).\\nIn logistic regression, we observe binary outcome and predictors, and \\nwe wish to draw inferences about the probability of an event in the popu-\\nlation. Suppose in a population from which we are sampling, each indi-\\nvidual has the same probability p, that an event occurs. For each individ-\\nual in our sample of size n, Yi=1 indicates that an event occurs for the ith \\nsubject, otherwise, Yi=0. The observed data are Y1, . . . , Yn and X1, . . .  , Xn \\nThe joint probability of the data (the likelihood) is given by \\ni=1n\\nL=∏ p (y⁄x)Yi (1-p (y⁄x))1-Yi =p (y⁄x)         (1-p (y⁄x))n-n∑i=1Yin∑i=1Yi\\nNatural logarithm of the likelihood is \\n(               )i=1 i=1n n\\nl=log (L)=∑ Yi log [p (y⁄x)]+  n-∑ Yi   log [1-p (y⁄x)] \\nIn which \\np (y⁄x)=                     ea+βχ\\n1 + ea+βχ\\nEstimating the parameters α and β is done using the first derivatives of \\nlog-likelihood, and solving them for α and β. For this, iterative computing is \\nused. An arbitrary value for the coeﬃcients (usually 0) is first chosen. Then \\nlog-likelihood is computed and variation of coefficients values observed. \\nReiteration is then performed until maximization of l (equivalent to maxi-\\nmizing L). The results are the maximum likelihood estimates of α and β.EVALUATION OF A LOGISTIC REGRESSION MODEL\\nThere are several parts involved in the evaluation of the logistic regres-\\nsion model. First, the overall model (relationship between all of the inde-\\npendent variables and dependent variable) needs to be assessed. Second, \\nthe importance of each of the independent variables needs to be as-\\nsessed. Third, predictive accuracy or discriminating ability of the model \\nneeds to be evaluated. Finally, the model needs to be validated.\\n1. Overall model evaluation\\n1)\\x08The\\x08likelihood\\x08 ratio\\x08test\\nOverall fit of a model shows how strong a relationship between all of the \\nindependent variables, taken together, and dependent variable is. It can be \\nassessed by comparing the fit of the two models with and without the in-\\ndependent variables. A logistic regression model with the k independent \\nvariables (the given model) is said to provide a better fit to the data if it \\ndemonstrates an improvement over the model with no independent vari-\\nables (the null model). The overall fit of the model with k coeﬃcients can \\nbe examined via a likelihood ratio test which tests the null hypothesis \\nH0 : β1=β2=. . .=βk=0.\\nTo do this, the deviance with just the intercept (-2 log likelihood of \\nthe null model) is compared to the deviance when the k independent \\nvariables have been added (-2 log likelihood of the given model). Likeli-\\nhood of the null model is the likelihood of obtaining the observation if \\nthe independent variables had no effect on the outcome. Likelihood of \\nthe given model is the likelihood of obtaining the observations with all \\nindependent variables incorporated in the model. \\nThe difference of these two yields a goodness of fit index G, χ2 statistic \\nwith k degrees of freedom (Bewick, Cheek, & Ball, 2005). This is a mea-\\nsure of how well all of the independent variables affect the outcome or \\ndependent variable. \\nG=χ2=(-2 log likelihood of null model)-(-2 log likelihood of given model)\\nAn equivalent formula sometimes presented in the literature is \\n= -2 log    likelihood of the null model\\n                    likelihood of the given model\\nwhere the ratio of the maximum likelihood is calculated before taking \\nthe natural logarithm and multiplying by -2. The term ‘likelihood ratio \\ntest’ is used to describe this test. If the p-value for the overall model fit \\nstatistic is less than the conventional 0.05, then reject H0 with the conclu-', metadata={'source': 'An_Introduction_to_Logistic_Regression_From_Basic_.pdf', 'page': 4}),\n",
       " Document(page_content='159\\nhttp://dx.doi.org/10.4040/jkan.2013.43.2.154 www.kan.or.krAn\\x08Introduction\\x08to\\x08Logistic\\x08Regression:\\x08From\\x08Basic\\x08Concepts\\x08to\\x08Interpretation\\x08with\\x08Particular\\x08Attention\\x08to\\x08Nursing\\x08Domain\\x08\\x08\\x08\\x08\\nsion that there is evidence that at least one of the independent variables \\ncontributes to the prediction of the outcome. \\n2)\\x08Chi-Square\\x08 Goodness\\x08 of\\x08Fit\\x08Tests\\x08\\nWith logistic regression, instead of R2 as the statistics for overall fit of \\nthe linear regression model, deviance between observed values from the \\nexpected values is used. In linear regression, residuals can be defined as \\nyi-ŷi, where yi is the observed dependent variable for the ith subject, and \\nŷi the corresponding prediction from the model. The same concept ap-\\nplies to logistic regression, where yi is equal to either 1 or 0, and the cor-\\nresponding prediction from the model is as\\nŷi=exp (α+β1xi1+. . .+βkxik) \\n1+exp (α+β1xi1+. . .+βkxik)\\nChi-square test can be based on the residuals, yi-ŷi (Peng & So, 2002). \\nA standardized residual can be defined as\\nri=yi-ŷi\\nŷi (1-ŷi )\\nwhere the standard deviation of the residuals is ŷi(1-ŷi). One can then \\nform a χ2 statistic as\\ni=1n\\nχ2=∑ ri2\\nThis statistic follows a  χ2 distribution with n−(k+1) degrees of freedom, \\nso that p-values can be calculated.  \\n3)\\x08Hosmer\\x08-\\x08Lemeshow \\x08test\\nThe Hosmer–Lemeshow test is to examine whether the observed pro-\\nportions of events are similar to the predicted probabilities of occurrence \\nin subgroups of the model population. The Hosmer-Lemeshow test is \\nperformed by dividing the predicted probabilities into deciles (10 groups \\nbased on percentile ranks) and then computing a Pearson Chi-square that \\ncompares the predicted to the observed frequencies in a 2-by-10 table. \\nThe value of the test statistics is \\n \\ng=110\\nH=∑(Og-Eg)2\\nEg \\nwhere Og and Eg denote the observed events, and expected events for the \\ngth risk decile group. The test statistic asymptotically follows a χ2 distri-\\nbution with 8 (number of groups -2) degrees of freedom. Small values (with large p-value closer to 1) indicate a good fit to the data, therefore, \\ngood overall model fit. Large values (with p<.05) indicate a poor fit to \\nthe data. Hosmer and Lemeshow do not recommend the use of this test \\nwhen there is a small n less than 400 (Hosmer & Lemeshow, 2000).\\n2. Statistical significance of individual regression coefficients\\nIf the overall model works well, the next question is how important each \\nof the independent variables is. The logistic regression coeﬃcient for the \\nith independent variable shows the change in the predicted log odds of \\nhaving an outcome for one unit change in the ith independent variable, all \\nother things being equal. That is, if the ith independent variable is changed \\n1 unit while all of the other predictors are held constant, log odds of out-\\ncome is expected to change bi units. There are a couple of different tests de-\\nsigned to assess the significance of an independent variable in logistic re-\\ngression, the likelihood ratio test and the Wald statistic (Menard, 2001).  \\n1)\\x08Likelihood\\x08 ratio\\x08test\\nThe likelihood-ratio test used to assess overall model fit can also be \\nused to assess the contribution of individual predictors to a given model. \\nThe likelihood ratio test for a particular parameter compares the likeli-\\nhood of obtaining the data when the parameter is zero (L0) with the like-\\nlihood (L1) of obtaining the data evaluated at the MLE of the parameter. \\nThe test statistic is calculated as follows:\\nG=-2 ln         =-2 (ln L0-ln L1)L0\\nL1 \\nThis statistics is compared with a χ2 distribution with 1 degree of free-\\ndom. To assess the contribution of individual predictors one can enter \\nthe predictors hierarchically, then compare each new model with the \\nprevious model to determine the contribution of each predictor. \\n2)\\x08Wald\\x08statistic\\nThe Wald statistic can be used to assess the contribution of individual \\npredictors or the significance of individual coeﬃcients in a given model \\n(Bewick et al., 2005). The Wald statistic is the ratio of the square of the \\nregression coefficient to the square of the standard error of the coeffi-\\ncient. The Wald statistic is asymptotically distributed as a Chi-square \\ndistribution.\\nW j= βj 2\\nSEβj 2 \\nEach Wald statistic is compared with a Chi-square with 1 degree of ', metadata={'source': 'An_Introduction_to_Logistic_Regression_From_Basic_.pdf', 'page': 5}),\n",
       " Document(page_content='160\\nhttp://dx.doi.org/10.4040/jkan.2013.43.2.154 www.kan.or.krPark,\\x08Hyeoun-Ae\\nfreedom. Wald statistics are easy to calculate but their reliability is ques-\\ntionable. \\n3)\\x08Odds\\x08ratios\\x08with\\x0895%\\x08CI\\nOdds ratio with 95% confidence interval (CI) can be used to assess the \\ncontribution of individual predictors (Katz, 1999). It is important to note \\nhowever, that unlike the p value, the 95% CI does not report a measure’s \\nstatistical significance. It is used as a proxy for the presence of statistical \\nsignificance if it does not overlap the null value (e.g. OR=1). \\nThe 95% CI is used to estimate the precision of the OR. A large CI in-\\ndicates a low level of precision of the OR, whereas a small CI indicates a \\nhigher precision of the OR. An approximate confidence interval for the \\npopulation log odds ratio is \\n95% CI for the In (OR)=In (OR)±1.96×{SE In (OR)}\\nwhere ln(OR) is the sample log odds ratio, and SE ln(OR) is the standard \\nerror of the log odds ratio(Morris & Gardner, 1988). Taking the antilog, \\nwe get the 95% confidence interval for the odds ratio:\\n95% CI for OR=eIn (OR)±1.96×{SE In (OR)}\\n3. Predictive Accuracy and Discrimination \\n1)\\x08Classification\\x08 table\\nThe classification table is a method to evaluate the predictive accuracy \\nof the logistic regression model (Peng & So, 2002). In this table the ob-\\nserved values for the dependent outcome and the predicted values (at a \\nuser defined cut-off value) are cross-classified. For example, if a cutoff \\nvalue is 0.5, all predicted values above 0.5 can be classified as predicting \\nan event, and all below 0.5 as not predicting the event. Then a two-by-\\ntwo table of data can be constructed with dichotomous observed out-\\ncomes, and dichotomous predicted outcomes. \\nThe table has following form.If the logistic regression model has a good fit, we expect to see many \\ncounts in the a and d cells, and few in the b and c cells. In an analogy \\nwith medical diagnostic testing, we can consider sensitivity=a/(a+b) \\nand specificity=d/(c+d). Higher sensitivity and specificity indicate a \\nbetter fit of the model.\\n2)\\x08Discrimination\\x08 with\\x08ROC\\x08curves\\nExtending the above two-by-two table idea, rather than selecting a \\nsingle cutoff, the full range of cutoff values from 0 to 1 can be examined. \\nFor each possible cutoff value, a two-by-two table can be formed. Plot-\\nting the pairs of sensitivity and one minus specificity on a scatter plot \\nprovides an ROC (Receiver Operating Characteristic) curve. The area \\nunder this curve (AUC) provides an overall measure of fit of the model \\n(Bewick, Cheek, & Ball, 2004). The AUC varies from 0.5 (no predictive \\nability) to 1.0 (perfect predictive ability). Larger AUC indicates better \\npredictability of the model. Points above the diagonal dividing the ROC \\nspace represent good classification results (better than random), while \\npoints below represent the poor results (worse than random).\\n4. Validation of the logistic regression\\nLogistic regression models are frequently used to predict a dependent \\nvariable from a set of independent variables. An important question is \\nwhether results of the logistic regression analysis on the sample can be \\nextended to the population the sample has been chosen from. This ques-\\ntion is referred as model validation. In practice, a model cab be validated \\nby deriving a model and estimating its coeﬃcients in one data set, and \\nthen using this model to predict the outcome variable from the second \\ndata set, then check the residuals, and so on.\\nWhen a model is validated using the data on which the model was de-\\nveloped, it is likely to be over-estimated. Thus, the validity of model \\nshould be assessed by carrying out tests of goodness of fit and discrimi-\\nnation on a different data set (Giancristofaro & Salmaso, 2003). If the \\nmodel is developed with a sub sample of observations and validated with \\nthe remaining sample, it is called internal validation. The most widely \\nused methods for obtaining a good internal validation are data-split-\\nting, repeated data-splitting, jackknife technique and bootstrapping \\n(Harrell, Lee, & Mark, 1996).\\nIf the validity is tested with a new independent data set from the same \\npopulation or from a similar population, it is called external validation. \\nObtaining a new data set allows us to check the model in a different con-Table 1. Sample Classification Table \\nObservedPredicted\\n1 0\\n1 a b\\n0 c d\\na, b, c, and d are number of observations in the corresponding cells.', metadata={'source': 'An_Introduction_to_Logistic_Regression_From_Basic_.pdf', 'page': 6}),\n",
       " Document(page_content='161\\nhttp://dx.doi.org/10.4040/jkan.2013.43.2.154 www.kan.or.krAn\\x08Introduction\\x08to\\x08Logistic\\x08Regression:\\x08From\\x08Basic\\x08Concepts\\x08to\\x08Interpretation\\x08with\\x08Particular\\x08Attention\\x08to\\x08Nursing\\x08Domain\\x08\\x08\\x08\\x08\\ntext. If the first model fits the second data set, there is some assurance of \\ngeneralizability of the model. However, if the model does not fit the sec-\\nond data, the lack of fit can be either due to the different contexts of the \\ntwo data sets, or true lack of fit of the first model. \\nREPORTING AND INTERPRETING LOGISTIC \\nREGRESSION RESULTS\\nIn presenting the logistic regression results, following four types of infor-\\nmation should be included: a) an overall evaluation of the logistic model; b) \\nstatistical tests of individual predictors; c) goodness-of-fit statistics; and d) \\nan assessment of the predicted probabilities. Table 2, 3, and 4 are examples \\nto illustrate the presentation of these four types of information. \\nTable 2 presents the statistical significance of individual regression co-\\neﬃcients (βs) tested using the Wald Chi-square statistic. According to \\nTable 2, Cholesterol was a significant predictor for event (p<.05). The \\nslope coeﬃcient 1.48 represents the change in the log odds for a one unit \\nincrease in cholesterol. The test of the intercept (p<.05) was significant \\nsuggesting that the intercept should be included in the model. Odd ratio \\n4.04 indicates that the odds for a event increase 4.04 times when the \\nvalue of the cholesterol is increased by 1 unit.\\nTable 3 presents three inferential statistical tests for overall model \\nevaluation: the likelihood ratio, score, and Wald tests. All three tests \\nyield similar conclusions for the given data set, namely that given logistic \\nmodel with independent variables was more effective than the null \\nmodel. Table 3 also presents an inferential goodness-of-fit test, the \\nHosmer-Lemeshow test. Hosmer-Lemeshow test statistics 7.76 was in-\\nsignificant (p>.05), suggesting that the model was fit to the data well. \\nTable 4 presents the degree to which predicted probabilities agree with \\nactual outcomes in a classification table. The overall correct prediction, \\n66.84% shows an improvement over the chance level which is 50%. With \\nthe classification table, sensitivity, specificity, false positive and false neg-\\native can be measured. Sensitivity measures the proportion of correctly \\nclassified events, whereas specificity measures the proportion of cor-rectly classified nonevents. The false positive measures the proportion of \\nobservations misclassified as events over all of those classified as events. \\nThe false negative therefore measures the proportion of observations \\nmisclassified as nonevents over all of those classified as nonevents.\\nCAUTIONS AND CONSIDERATIONS\\nIn logistic regression no assumptions are made about the distribu-\\ntions of the independent variables. However, the independent variables \\nshould not be highly correlated with one another because this could \\ncause problems with estimation. \\nStudies with small to moderate samples size employing logistic regres-\\nsion overestimate the effect measure. Thus, large sample sizes are re-\\nquired for logistic regression to provide suﬃcient numbers in both cate-\\ngories of the outcome variable. Also, the more independent variables \\nwere included, the larger the sample size is required. With small sample \\nsizes, the Hosmer–Lemeshow test has low power and is unlikely to de-\\ntect subtle deviations from the logistic model. Hosmer and Lemeshow \\nrecommend sample sizes greater than 400 (Hosmer & Lemeshow, 2000).\\nTable 2. Example Output from Logistic Regression: Statistical Tests of Individual Predictors\\nPredictor   ß SE (ß) Wald’s χ2df p eß (OR)95% CI for OR\\nLower Upper\\nCholesterol  1.48 0.45 10.98 1 <.001 4.04 1.83 10.58\\nConstant -12.78 1.98 44.82 1 <.001\\nCI=Confidence interval; df =Degrees of freedom; OR =Odds ratio; SE =Standard error.Table 3. Example Output from Logistic Regression: Overall Model \\nEvaluation and Goodness -of-Fit Statistics\\nTest Categories   χ2df p\\nOverall model evaluation Likelihood ratio test 12.02 2 .002\\nScore test 11.52 2 .003\\nWald test 11.06 2 .004\\nGoodness -of-fit test Hosmer & Lemeshow  7.76 8 .457\\nTable 4. Example Output from Logistic Regression: A Classification Table\\nObservedPredicted\\n% Correct\\nYes No\\nYes 3 57  5.00\\nNo 6 124 95.48\\nOverall % correct 66.84\\nSensitivity =3/(3+57)=5.00%; Specificity =124/(6 +124)=95.48%;\\nFalse positive =6/(6+124)=4.62%; False negative =57/(3+57)=95.00%.', metadata={'source': 'An_Introduction_to_Logistic_Regression_From_Basic_.pdf', 'page': 7}),\n",
       " Document(page_content='162\\nhttp://dx.doi.org/10.4040/jkan.2013.43.2.154 www.kan.or.krPark,\\x08Hyeoun-Ae\\nANALYSIS OF USE OF LOGISTIC REGRESSION IN NURSING\\nOriginal research articles containing explicit mention of LR were \\nsearched in the Journal of Korean Academy of Nursing published be-\\ntween 2010 and 2012. In total 23 articles were identified. There are 11 ar-\\nticles performed logistic regression with secondary data from large sur-\\nveys, six articles from the cross-sectional survey, four articles from the \\nprospective studies and two from the retrospective case-control studies. \\nTo evaluate the research reports, a list of criteria from Bagley et al.’s \\n(2001) study was used. None of the studies reported any interaction and \\nonly one study reported a validation of the model with threefold cross \\nvalidation technique, so those columns have been omitted. \\nTable 5 shows the adherence to the guidelines for using and reporting \\nLR for each of the 23 articles. Although it is important the logistic regres-\\nsion model includes all relevant variables, it is also important the model \\nnot start with more variables than are justified for the given number of \\nobservations (Peduzzi et al., 1996). Peduzzi et al. suggested that the num-\\nber of the less common of the two possible outcomes divided by the \\nnumber of independent variables should be at least 10 as a useful rule of \\nthumb. For analysis of 23 articles, the number of events-per-variable \\nranged from 0.7 to 16409. Sixteen of 23 of the analyses had an events-\\nper-variable ratio above 10. Sample size calculation was mentioned in \\n11 articles. Five out of 11 used G*Power to calculate the sample size. \\nFor best results from the use of logistic regression, any given change in \\na continuous independent variable should have the same effect on the \\nlog-odds of a positive outcome. However, in all the studies with contin-\\nuous or ordinal independent variables, none tested the conformity with \\nthe linear gradient for continuous variables. As noted before, no interac-\\ntions were reported in any of 23 studies. However, it is unclear whether \\ninteractions were considered but not found to be significant or whether \\ninteractions were not considered. If two highly correlated variables are \\nincluded in the model, then their estimated contributions may be impre-\\ncise. Thus collinearity should be tested. However, only 5 of the 23 studies \\nmentioned collinearity with the details of testing. Again it is not clear \\nwhether collinearities was considered but not found to be significant or \\nwhether collinearities were not considered. As noted before, only one \\nstudy reported the model validation. \\nAll of the studies reported measures of statistical significance, typi-\\ncally confidence intervals and P-values for each of the independent \\nvariables. Sometimes, these statistics were reported only for those vari-\\nables found to be significant. The statistical significance for the entire model was reported for 13 of the 23 analyses. Goodness of fit measures \\ndescribing how well the entire model matches the observed values were \\nreported in 9 articles. \\nNearly all the articles explained how variables were selected for inclu-\\nsion in the model. Most of the articles selected variables based on the lit-\\nerature review. However, 15 of 23 reported performing the statistical \\ntests (such as bivariate analyses) before considering the variable for the \\nmodels. None of the articles provided complete details on the coding for \\nall the variables. However, it was possible to infer the coding from the \\ntextual description in all cases. Eight studies explicitly stated the fitting \\nprocedure. In one study the variables included in the model was deter-\\nmined in hierarchically grouped subsets. \\nCONCLUSION\\nLogistic regression is a type of multivariable analyses used with in-\\ncreasing frequency in the nursing domain because of its ability to model \\nthe relationship between dichotomous dependent variable and one or \\nmore independent variables. In this paper, logistic regression from basic \\nconcepts to interpretation of analysis results was introduced. In addition, \\ntwenty-three articles published between 2010 and 2011 in the Journal of \\nKorean Academy of Nursing were examined to see if logistic regressions \\nwere properly used and reported.  \\nIt was found that there were substantial shortcomings in the use and \\nreporting of logistical regression results. Most notably, one-thirds of the \\nstudies had not enough sample size with events-per-variables ratios be-\\nlow 10, suggesting that the regression results may not be reliable. Only \\none study reported internal validation analysis. Validation is a crucial \\nstep to test the regression model captured essential relationships in the \\ndomain of study. Another problem is that only five studies reported tests \\nfor collinearity. If there is high correlation between two independent \\nvariables, variance of the coeﬃcients of these variables will be increased, \\nwith a consequent loss of statistical significance. In addition, none re-\\nported tests for any conformity with the linear gradient for continuous \\nindependent variables, and tests for interactions. These problems repre-\\nsent failures to perform important aspect of the analysis or failures to re-\\nport details of the analyses. It is hard to distinguish these two possibili-\\nties by reviewing published articles. \\nThus, proper use and report of this powerful and sophisticated model-\\ning technique requires considerable care both in the specification of the \\nmodel and in the estimation and interpretation of the model’s coeﬃcients. ', metadata={'source': 'An_Introduction_to_Logistic_Regression_From_Basic_.pdf', 'page': 8}),\n",
       " Document(page_content='163\\nhttp://dx.doi.org/10.4040/jkan.2013.43.2.154 www.kan.or.krAn\\x08Introduction\\x08to\\x08Logistic\\x08Regression:\\x08From\\x08Basic\\x08Concepts\\x08to\\x08Interpretation\\x08with\\x08Particular\\x08Attention\\x08to\\x08Nursing\\x08Domain\\x08\\x08\\x08\\x08\\nTable 5. Adherence to Guidelines for Using and Reporting Logistic Regression\\nAuthor Event per \\nvariableCollinearity Statistical testGoodness  of fitVariable selectionCoding of variablesFitting procedureNumber of observationsSample size calculationType of study\\nJung & Lee 262/7\\n=29.1 Mentioned, \\ntested by VIFVariables: OR, CI, p \\nModel: Hosmer - \\nLemeshowHosmer -\\nLemeshowYes, p<.05 Yes Stepwise 1,458 No Secondary analysis of 4th \\nKorean National Health \\nand Nutrition Examination Survey\\nCho & Chung 205/17\\n=12.1 NR Variables: B, CI, p \\nModel: Wald Chi -square, \\nAIC, R2, Hosmer -\\nLemeshow Goodness     of fit testHosmer\\n-\\nLemeshowYes, p<.05 No Forward \\nstepwise3,348 No Retrospective cohort study\\nLee, Jung, Yun, \\nUm, & Jee142/4=35.5 NR Variables: B, SE, Wald, OR, \\nCI, p \\nModel: Hosmer -Lemeshow \\nGoodness of fit test, Chi -\\nSquare, ROC curve, Correct prediction, \\nNagelkerke R\\n2Hosmer -\\nLemeshowYes, p<.05 No Forward \\nstepwise401 Mentioned\\n(Tabachnick & \\nFidell)Secondary Analysis of Survey\\nKim & Kim 114863/7 =\\n  16409NR Variables: B, SE, OR, CI, p \\nModel: NRNR Informal No Generalized \\nestimating equation logistic regression254,414 No National Health Insurance \\nData\\nYi, Yi, & Jung 2700/20\\n=135 NR Variables: OR, CI Model: NRNR Yes, p\\n<.001 Yes NR 17783 No Korea Youth Health Risk \\nBehavior Web -based \\nSurvey\\nYeoum & Lee 181/4=43 Mentioned, \\ntested by Collinearity statistics Tolereance, VIFVariables: OR, CI, p \\nModel: \\n-2LL, Chi -Square, \\nAUCNR Yes, p<.05 Yes NR 732 No Survey\\nCha, Cho, & \\nYoo26/3=8.7 NR Variables: OR, CI, p \\nModel: NRNR Yes, p<.05 Stepwise 103 Mentioned(Korinek)Retrospective case\\n-control \\nstudy\\nChoi & Lee 123/20 =6.1 NR Variables: OR, CI, p \\nModel: Hosmer -Lemeshow \\nGoodness of fit test, Nagelkerke R\\n2, Correct \\npredictionHosmer -\\nLemeshowInformal Yes NR 246 Mentioned(Biderman, \\nFried & Galinsky)Case\\n-control study \\nInterview and survey with \\nsecondary data from public health center records\\nChoi, Jung, \\nKim, & Park318/15\\n=21.2 Mentioned, \\ntested by VIFVariables: OR, CI, p \\nModel: Hosmer - Lemeshow \\nGoodness of fit testHosmer -\\nLemeshowInformal Hierarchical,  \\nin 3 blocks9094 NR Secondary analysis \\nof  Korean Working            Condition Survey\\nPark, & Jung 60/4\\n=15 Mentioned, \\ntested by Collinearity statistics Tolereance, VIFVariables: OR, CI Model: NRYes, p\\n<.05 NR 804 NR Survey\\nKim & Park 756/2=378 NR Variables: OR, CI, p \\nModel: NRInformal NR 6,521 NR Secondary Analysis of  \\nHealth Interview and Health Behavior Surveys\\nCho & Yoo \\nYang & 88/3=29.3 NR Variables: OR, CI, p \\nModel: -2LL, AIC, ScoreYes, p<.05 NR 276 G*Power Survey\\nKim 103/8=12.9 NR Variables: OR, CI, p \\nModel: NRYes, p<.05 NR 324 G*Power Survey\\nChoi, Park,      \\n& Lee249/9= 27.7 NR Variables: B, SE, Wald, OR, \\nCI, p \\nModel: NRYes, p<.05 NR 3,024 Mentioned Secondary Analysis of  \\nSurvey\\nYeon et al. 451/11 = 41 NR Variables: OR, CI \\nModel: NRYes, p<.05 NR 2,639 NR Secondary Analysis of \\nCommunity Health Survey', metadata={'source': 'An_Introduction_to_Logistic_Regression_From_Basic_.pdf', 'page': 9})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Iniciamos el objeto lector de PDF\n",
    "loader = PyPDFLoader(\"An_Introduction_to_Logistic_Regression_From_Basic_.pdf\")\n",
    "\n",
    "# Lo cargamos\n",
    "file   = loader.load()\n",
    "\n",
    "# Vemos que contiene nuestro archivo\n",
    "file[: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfb8a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de elementos cargados -->  11\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de elementos cargados --> \", len(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ee17b",
   "metadata": {},
   "source": [
    "Vemos que se ha cargado un documento con información no estructurada, con tantas páginas como diapositivas, no obstante, es recomendable no pasar toda esta información de golpe a los modelos GPT, por lo que se recurre comúmente a técnicas de _chunking_ es decir, obtener pequeños fragmentos o porciones del documento (_chunks_) sobre los cuáles podamos ir trabajando en pequeños batches.\n",
    "\n",
    "Para ir dividiendo la información del archivo PDF en pequeños fragmentos volvemos a emplear funciones de LangChain, en este caso, la función que podemos encontrar desde `text_splitter` https://python.langchain.com/docs/modules/data_connection/document_transformers/ `RecursiveCharacterTextSplitter()`\n",
    "\n",
    "En otras palabras, con `RecursiveCharacterTextSplitter` lo que hace es, desde nuestro PDF ir dividiendo en párrafos, frases y palabras.\n",
    "\n",
    "https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd198715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size      = 200,\n",
    "    chunk_overlap   = 20,\n",
    "    length_function = len,\n",
    "    add_start_index = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0139557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora dividimos los documentos de nuestro PDF\n",
    "chunks = text_splitter.split_documents(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32276156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de Chunks producidos desde nuestro PDF -->  320\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de Chunks producidos desde nuestro PDF --> \", len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123f25c8",
   "metadata": {},
   "source": [
    "## Embeddings <a name=\"embeddings\"></a>\n",
    "\n",
    "Una vez que tenemos separado en pequeños fragmentos nuestro documento PDF, ya podemos obtener los vectores de Word Embeddings sobre el mismo, para posteriormente, poder almacenarlos en Pinecone. \n",
    "\n",
    "Si realizamos todo este proceso de cero, tendríamos que pasar por una interesante tarea de limpieza de texto (recordar que, en cierto modo seguimos trabajando con datos raw) y, posteriormente entrenar un modelo de vectorización propio con Word2Vec, pero, de nuevo aparece LangChain para proporcionarnos una enorme gama de modelos pre-entrenados que son capaces de crear Embeddings, esto, se consigue desde las funciones `embeddings` https://python.langchain.com/docs/modules/data_connection/text_embedding/ desde LangChain podemos acceder a los modelos de Embeddings como:\n",
    "+ HuggingFace\n",
    "+ OpenAI\n",
    "+ Bedrock (AWS)\n",
    "+ PalM (Google)\n",
    "+ spaCy\n",
    "+ Ollama\n",
    "+ Etc... https://python.langchain.com/docs/integrations/text_embedding/\n",
    "\n",
    "Dada la dimensionalidad de nuestros vectores, vamos a cargar los Embeddings desde __HuggingFace__ https://python.langchain.com/docs/integrations/text_embedding/huggingfacehub\n",
    "\n",
    "IMPORTANTE: Para buscar el modelo adecuado debemos investigar dentro de HuggingFace modelos que soporten creación de Embeddings, una opción puede ser los modelos de la familia sentence-transformers https://huggingface.co/sentence-transformers\n",
    "\n",
    "En nuestro caso, vamos a cargar un modelo ligero como el multilingual `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
    "\n",
    "Este modelo tiene una dimensionalidad de 384 que es justo lo que estamos utilizando dentro de nuestra demo.\n",
    "\n",
    "Para poder trabajar con los modelos de sentence-transformers debemos instalar previamente el paquete:\n",
    "```python\n",
    "!pip install sentence_transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b26e6f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "emb_model = HuggingFaceEmbeddings(model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ea4b3",
   "metadata": {},
   "source": [
    "Una vez descargado el modelo, podemos realizar alguna prueba para comprobar cómo realiza los Embeddings, esto, se consigue desde las funciones de codificación (encoder) y decodificación (decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a82cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cargamos el modelo \n",
    "model = SentenceTransformer(model_name_or_path = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Obtenemos Embeddings\n",
    "emb_query = model.encode(\"Explícame qué es una regresión lineal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb37e02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionalidad de los Embeddings -->  384\n",
      "[-0.48585448 -0.0671955   0.00969446 -0.0858185   0.32764772]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensionalidad de los Embeddings --> \", len(emb_query))\n",
    "print(emb_query[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b026d1",
   "metadata": {},
   "source": [
    "## Carga de los Embeddings en Pinecone <a name=\"persist\"></a> \n",
    "\n",
    "Ahora, ya sabemos cómo vamos a conseguir qué preguntando en lenguaje natural, nuestras querys se puedan codificar como Embeddings, pero, todavía no hemos insertado nuestros documentos como Embeddings en Pinecone.\n",
    "\n",
    "Para insertar documentos en Pinecone vuelve a ayudarnos notiramente LangChain, ya que tiene integraciones directas con múltiples bases de datos vectoriales https://python.langchain.com/docs/modules/data_connection/vectorstores/\n",
    "\n",
    "Desde las funciones de `vectorsotres` podemos buscar la función que inicie la conexión con nuestro proveedor de base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f856f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e184c8fb",
   "metadata": {},
   "source": [
    "La función de Pinecone (como vector store) que se encarga de poder almacenar información como Embeddings de forma automática, en nuestro caso de uso es `from_documents` ya que tenemos los chunks creados previamente, además debemos pasarle el nombre de nuestro índice de Pinecone y, el modelo ya creado de Embeddings.\n",
    "\n",
    "NOTA: La conexión (`pinecone.init()`) debe estar activa antes de hacer ese paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e047b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"\"\n",
    "PINECONE_ENV     = \"gcp-starter\"\n",
    "INDEX_NAME       = \"demo1\"\n",
    "\n",
    "import pinecone\n",
    "\n",
    "pinecone.init( \n",
    "    api_key      = PINECONE_API_KEY,\n",
    "    environment  = PINECONE_ENV\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37c761f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.pinecone.Pinecone at 0x22a33e4dba0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subimos nuestros documentos\n",
    "Pinecone.from_documents(\n",
    "    documents  = chunks,     # Chunks de nuestros documentos\n",
    "    embedding  = emb_model,  # Modelo ya cargado de embeddings\n",
    "    index_name = INDEX_NAME  # Nombre del Index Pinecone\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dd40ec",
   "metadata": {},
   "source": [
    "## Integración con OpenAI y generación de prompts <a name=\"openai\"></a> \n",
    "\n",
    "Lo primero de todo, debemos instalar la librería de OpenAI\n",
    "```python\n",
    "!pip install openai\n",
    "```\n",
    "\n",
    "Tal y como hemos hablado de LangChain, es el punto de unión entre la BD Vectorial (Pinecone) y el LLM (OpenAI), por lo tanto, de nuevo con LangChain obtendremos funciones que nos ayuden a conectar estos dos mundos, para este propósito necesitamos:\n",
    "+ Generación del chat - De OpenAI https://python.langchain.com/docs/modules/model_io/chat\n",
    "+ Tipo de chat - En un sistema RAG generalmente lo implementamos mediante _question and answering_ Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00dd9af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019b91e",
   "metadata": {},
   "source": [
    "Los pasos siguientes serían:\n",
    "+ Definir la base de datos y el modelo de Embeddings\n",
    "+ Lanzar el chat con un modelo LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec3a1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la conexión de la BD y el modelo de Embeddings\n",
    "\n",
    "bbdd_vectorial = Pinecone.from_existing_index(\n",
    "    index_name = INDEX_NAME, # Pinecone Index\n",
    "    embedding  = emb_model   # Modelo de Embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50861c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el chat con un LLM\n",
    "# https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html\n",
    "OPENAI_API_KEY = \"\"\n",
    "\n",
    "# Configuración del chat\n",
    "llm_model = ChatOpenAI(\n",
    "    openai_api_key = OPENAI_API_KEY,\n",
    "    model_name     = \"gpt-3.5-turbo\",  # Nombre del modelo de OpenAI https://platform.openai.com/docs/models\n",
    "    temperature    = 0.8               # Entre 0 y 1, la creatividad del modelo (Alucinaciones)\n",
    ")\n",
    "\n",
    "# Conexión con LangChain - Tipo Q&A\n",
    "chat_chain = load_qa_chain(\n",
    "    llm       = llm_model,\n",
    "   chain_type = \"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e464559",
   "metadata": {},
   "source": [
    "Una vez definida la configuracíon general del chat, ya podemos comenzar a hacer preguntas a nuestro \"propio _ChatGPT_\" !! Existen diversas formas de crear _prompts_ en nuestro caso, vamos a implementarlo de una forma simple en dos fases:\n",
    "1. Obteniendo la similaridad de vectores con `similarity_search`\n",
    "2. Lanzando el promt con la función `chat_chain.run()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4a4831",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m similarity \u001b[38;5;241m=\u001b[39m bbdd_vectorial\u001b[38;5;241m.\u001b[39msimilarity_search(query \u001b[38;5;241m=\u001b[39m ask, \n\u001b[0;32m      5\u001b[0m                                               k     \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Prompt\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[43mchat_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_documents\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msimilarity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:510\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    506\u001b[0m         _output_key\n\u001b[0;32m    507\u001b[0m     ]\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m--> 510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    511\u001b[0m         _output_key\n\u001b[0;32m    512\u001b[0m     ]\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    516\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    518\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    311\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    312\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    314\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    297\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    298\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    299\u001b[0m     inputs,\n\u001b[0;32m    300\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 304\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:122\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m    121\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[1;32m--> 122\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_docs(\n\u001b[0;32m    123\u001b[0m     docs, callbacks\u001b[38;5;241m=\u001b[39m_run_manager\u001b[38;5;241m.\u001b[39mget_child(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mother_keys\n\u001b[0;32m    124\u001b[0m )\n\u001b[0;32m    125\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py:171\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[1;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs), {}\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\llm.py:298\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    284\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    311\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    312\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    314\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    297\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    298\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    299\u001b[0m     inputs,\n\u001b[0;32m    300\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 304\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\llm.py:108\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    105\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    106\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    107\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 108\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chains\\llm.py:120\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    118\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    121\u001b[0m         prompts,\n\u001b[0;32m    122\u001b[0m         stop,\n\u001b[0;32m    123\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    125\u001b[0m     )\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    128\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    129\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chat_models\\base.py:459\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    457\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    458\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chat_models\\base.py:349\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    348\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    350\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    351\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    353\u001b[0m ]\n\u001b[0;32m    354\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chat_models\\base.py:339\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 339\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    340\u001b[0m                 m,\n\u001b[0;32m    341\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    342\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    343\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    344\u001b[0m             )\n\u001b[0;32m    345\u001b[0m         )\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chat_models\\base.py:492\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    489\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    490\u001b[0m     )\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[1;32m--> 492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    493\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    494\u001b[0m     )\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chat_models\\openai.py:417\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    415\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    416\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 417\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    418\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    419\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langchain\\chat_models\\openai.py:339\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[1;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    341\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(\u001b[38;5;28mself\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_utils\\_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\resources\\chat\\completions.py:594\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    592\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    593\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py:1055\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1043\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1051\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1052\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1053\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1054\u001b[0m     )\n\u001b[1;32m-> 1055\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py:834\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    827\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    832\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    833\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m--> 865\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py:925\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m--> 865\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py:925\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\_base_client.py:877\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m--> 877\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "ask = \"¿How can i fit logistic regression model?\"\n",
    "\n",
    "# Similaridad\n",
    "similarity = bbdd_vectorial.similarity_search(query = ask, \n",
    "                                              k     = 4)\n",
    "\n",
    "# Prompt\n",
    "prompt = chat_chain.run(question = ask, input_documents = similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af589a7",
   "metadata": {},
   "source": [
    "Nota: Si tenemos el crédito gratuito agotado (al cabo de 3 meses aprecerá este error)\n",
    "    \n",
    "`Error Code 429 - You exceeded your current quota, please check your plan and billing details.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2d5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
