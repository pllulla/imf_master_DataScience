{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Anomaly Detection\n",
    "\n",
    "Generate a dataset with the following artificial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Generate train data\n",
    "X_inliers = 0.3 * np.random.randn(100, 2)\n",
    "X_inliers = np.r_[X_inliers + 2, X_inliers - 2]\n",
    "\n",
    "# Generate some outliers\n",
    "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
    "X = np.r_[X_inliers, X_outliers]\n",
    "\n",
    "n_outliers = len(X_outliers)\n",
    "ground_truth = np.ones(len(X), dtype=int)\n",
    "ground_truth[-n_outliers:] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Local Outlier Factor and get the following metrics:\n",
    "* Recall\n",
    "* F1-Score\n",
    "* Precission\n",
    "* Accuracy\n",
    "* ROC AUC\n",
    "\n",
    "(You can use in this exercise predict function)\n",
    "\n",
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confussion_matrix(matrix):\n",
    "    df_confussion_matrix = pd.DataFrame(matrix,\n",
    "                     ['True Normal','True Fraud'],\n",
    "                     ['Pred Normal','Pred Fraud'])\n",
    "    plt.figure(figsize = (8,4))\n",
    "    sns.set(font_scale=1.4)\n",
    "    plt.title('Confussion Matrix')\n",
    "    _ = sns.heatmap(df_confussion_matrix, annot=True, annot_kws={\"size\": 16}, fmt='g')\n",
    "    \n",
    "def model_reporting(y_real, y_pred):\n",
    "    confussion_matrix = metrics.confusion_matrix(y_real, y_pred)\n",
    "    roc_auc = metrics.roc_auc_score(y_real, y_pred)\n",
    "    metrica_f1 = metrics.f1_score(y_real, y_pred)\n",
    "    print('\\tAUC of ROC Curve is: {}'.format(round(roc_auc,2)))\n",
    "    print('\\tF1 Score: {}'.format(round(metrica_f1,2)))\n",
    "    print(\"\\tAccuracy: {}\".format(round(metrics.accuracy_score(y_real, y_pred),3)))  \n",
    "    print(\"\\tSensitivity:{}\".format(round(metrics.recall_score(y_real, y_pred),3)))\n",
    "    print(\"\\tPrecission: {}\".format(round(metrics.precision_score(y_real, y_pred),3)))   \n",
    "    plot_confussion_matrix(confussion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"X1\" : X[: ,0],\n",
    "    \"X2\" : X[: ,1],\n",
    "    \"Target\" : ground_truth\n",
    "})\n",
    "\n",
    "sns.pairplot(data=df, hue = \"Target\", palette=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model for outlier detection (default)\n",
    "clf = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "# use fit_predict to compute the predicted labels of the training samples\n",
    "# (when LOF is used for outlier detection, the estimator has no predict,\n",
    "# decision_function and score_samples methods).\n",
    "y_pred = clf.fit_predict(X)\n",
    "n_errors = (y_pred != ground_truth).sum()\n",
    "X_scores = clf.negative_outlier_factor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reporting(ground_truth, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Local Outlier Factor (LOF)\")\n",
    "plt.scatter(X[:, 0], X[:, 1], color=\"k\", s=3.0, label=\"Data points\")\n",
    "# plot circles with radius proportional to the outlier scores\n",
    "radius = (X_scores.max() - X_scores) / (X_scores.max() - X_scores.min())\n",
    "plt.scatter(\n",
    "    X[:, 0],\n",
    "    X[:, 1],\n",
    "    s=1000 * radius,\n",
    "    edgecolors=\"r\",\n",
    "    facecolors=\"none\",\n",
    "    label=\"Outlier scores\",\n",
    ")\n",
    "plt.axis(\"tight\")\n",
    "plt.xlim((-5, 5))\n",
    "plt.ylim((-5, 5))\n",
    "plt.xlabel(\"prediction errors: %d\" % (n_errors))\n",
    "legend = plt.legend(loc=\"upper left\")\n",
    "legend.legendHandles[0]._sizes = [10]\n",
    "legend.legendHandles[1]._sizes = [20]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
