{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo el dataset Iris\n",
    "dataset = load_iris()\n",
    "print(u'Los tipos de clases que hay en el dataset son: {}'.format(dataset.target_names))\n",
    "dataset.data[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos variables\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represento los datos originales con sus clases diferenciadas\n",
    "dfXY = pd.DataFrame(X, columns=dataset.feature_names)\n",
    "dfXY[\"target\"] = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=dfXY, \n",
    "             hue=\"target\", \n",
    "             vars=dfXY.columns[dfXY.columns != \"target\"], \n",
    "             diag_kind=\"hist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto se utiliza el método del codo para agrupar los datos X, es decir las variables predictoras pero no la clase de flor. El método del codo consiste en calcular la distancia media de las observaciones a su centroide para una serie de valores de k hasta encontrar un valor que satisfaga que un incremento de k no mejore sustancialmente la distancia media intra-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo WSS (Within-Cluster-Sum of Squared Errors) en función del \n",
    "# número de clústers k\n",
    "wss = []\n",
    "for K in range(2, 15):\n",
    "    \n",
    "    clf = KMeans(init=\"random\", random_state=0, n_clusters=K)\n",
    "    clf.fit(X)\n",
    "    resultados = cross_validate(clf, X, cv=4)\n",
    "    wss.append(np.mean(resultados[\"test_score\"]) * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represento el método del codo\n",
    "plt.plot(np.arange(2, 15), wss)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"WSS\")\n",
    "plt.title(\"Método del codo para obtener el K óptimo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo WSS (Within-Cluster-Sum of Squared Errors) en función del \n",
    "# número de clústers k\n",
    "wss = []\n",
    "for K in range(2, 30):\n",
    "    \n",
    "    clf = KMeans(init=\"random\", random_state=0, n_clusters=K)\n",
    "    clf.fit(X)\n",
    "    resultados = cross_validate(clf, X, cv=4)\n",
    "    wss.append(np.mean(resultados[\"test_score\"]) * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represento el método del codo\n",
    "plt.plot(np.arange(2, 30), wss)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"WSS\")\n",
    "plt.title(\"Método del codo para obtener el K óptimo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusto el modelo con el mejor parámetro k=3\n",
    "clf = KMeans(init=\"random\", random_state=0, n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los centroides\n",
    "clf.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector de asignación al cluster\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Es similar la cluserización al target original? (solo comprobación)\n",
    "dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtengo la lista de variables\n",
    "feat_list = [[x, y] for x in range(4) for y in range(4) if x != y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in feat_list:\n",
    "    \n",
    "    plt.figure(figsize=(10, 2.55))\n",
    "    plt.subplot(121)\n",
    "    plt.scatter(X[:, idx[0]], X[:, idx[1]], c=dfXY[\"target\"])\n",
    "    plt.xlabel(dataset.feature_names[idx[0]])\n",
    "    plt.ylabel(dataset.feature_names[idx[1]])\n",
    "    plt.title(\"Clases reales\")\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.scatter(X[:, idx[0]], X[:, idx[1]], c=clusters)\n",
    "    plt.xlabel(dataset.feature_names[idx[0]])\n",
    "    plt.ylabel(dataset.feature_names[idx[1]])\n",
    "    plt.title(u\"Asignación del clustering\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consideraciones práticas:\n",
    "\n",
    "* Preprocesamiento de datos: las variables X deben tener valores numéricos y continuos en la medida de lo posible. Del mismo modo es recomendable escalar los valores y no incluir variables muy correlacionadas. Generalmente se utiliza un método llamado “estandarización” de los datos.\n",
    "* K-medias vs K-medianas: existe otro algoritmo denominado K-medianas que es análogo al K-medias, pero en el que los centroides se obtienen a partir de la mediana. Este algoritmo es mejor utilizarlo cuando las variables tienen muchos outliers.\n",
    "\n",
    "### Cuando utilizarlo.\n",
    "\n",
    "* El algoritmo K-medias es útil aplicarlo cuando existe una definición por parte de negocio del número de grupos K en los que se quiere dividir el conjunto de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfXY[\"cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=dfXY, \n",
    "             hue=\"cluster\", \n",
    "             vars=dfXY.columns[(dfXY.columns != \"target\") & (dfXY.columns != \"cluster\")], \n",
    "             diag_kind=\"hist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfXY.groupby([\"cluster\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfXY.groupby([\"cluster\"]).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
